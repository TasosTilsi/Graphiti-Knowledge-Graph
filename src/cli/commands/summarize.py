"""Summarize command for knowledge graph.

Generates LLM-powered summaries of the entire knowledge graph or focused on a specific topic.
"""
import typer
from typing import Annotated, Optional
from rich.panel import Panel
from rich.markdown import Markdown

from src.models import GraphScope
from src.cli.output import console, print_error, print_json, print_warning
from src.cli.utils import resolve_scope, EXIT_ERROR
from src.llm import LLMUnavailableError


def _load_entities(scope: GraphScope, topic: Optional[str] = None) -> list[dict]:
    """Load relevant entities from the knowledge graph.

    Args:
        scope: Graph scope to query
        topic: Optional topic to filter entities

    Returns:
        List of entity dictionaries

    TODO: Wire to actual graph read operations when available.
    For now, returns mock data to enable CLI flow testing.
    """
    # Mock data for CLI testing
    if topic:
        # Simulate topic-filtered results
        if "architecture" in topic.lower():
            return [
                {"id": "1", "name": "CLI Architecture", "type": "decision"},
                {"id": "2", "name": "Typer Framework", "type": "technology"},
            ]
        elif "llm" in topic.lower():
            return [
                {"id": "3", "name": "Ollama Integration", "type": "decision"},
                {"id": "4", "name": "Cloud Failover Pattern", "type": "pattern"},
            ]
        else:
            # No results for unknown topics
            return []
    else:
        # Whole graph mock
        return [
            {"id": "1", "name": "CLI Architecture", "type": "decision"},
            {"id": "2", "name": "Typer Framework", "type": "technology"},
            {"id": "3", "name": "Ollama Integration", "type": "decision"},
            {"id": "4", "name": "Cloud Failover Pattern", "type": "pattern"},
            {"id": "5", "name": "Security Filtering", "type": "feature"},
        ]


def _generate_summary(entities: list[dict], topic: Optional[str] = None) -> str:
    """Generate LLM summary from entities.

    Args:
        entities: List of entity dictionaries
        topic: Optional topic focus

    Returns:
        Summary text generated by LLM

    TODO: Wire to actual LLM via src.llm.chat() when graph read operations available.
    For now, returns mock summary to enable CLI flow testing.
    """
    # TODO: Wire to actual LLM via src.llm.chat() when graph read operations available
    # Construct prompt
    # entities_str = "\n".join([f"- {e['name']} ({e['type']})" for e in entities])
    # prompt = f"Summarize the following knowledge graph entities: {entities_str}. "
    # prompt += "Focus on key decisions, patterns, and relationships."
    # if topic:
    #     prompt += f" Focus specifically on: {topic}"
    #
    # messages = [{"role": "user", "content": prompt}]
    # response = chat(messages)
    # return response['message']['content']

    # Mock summary for CLI testing
    if topic:
        return f"""## Knowledge Summary: {topic}

The knowledge graph contains {len(entities)} entities related to {topic}.

**Key Findings:**
- Primary architectural decisions documented
- Technology choices and integration patterns captured
- Implementation details and best practices recorded

**Relationships:**
- Strong connections between related concepts
- Clear dependency chains established
- Evolution of decisions tracked over time

This represents the current state of knowledge about {topic} in the system."""
    else:
        return f"""## Whole Graph Knowledge Summary

The knowledge graph contains {len(entities)} entities across multiple domains.

**Key Areas:**
- CLI Architecture and command design patterns
- LLM Integration with cloud/local failover
- Security filtering and secret detection
- Storage foundation with Kuzu database
- Project and global scope management

**Insights:**
- Consistent architectural patterns across subsystems
- Strong emphasis on developer experience
- Production-ready error handling and edge cases
- Well-documented decision rationale

This represents a comprehensive view of all project knowledge captured to date."""


def summarize_command(
    topic: Annotated[
        Optional[str],
        typer.Argument(help="Topic to summarize (omit for whole graph)")
    ] = None,
    global_scope: Annotated[
        bool,
        typer.Option("--global", "-g", help="Use global scope")
    ] = False,
    project_scope: Annotated[
        bool,
        typer.Option("--project", "-p", help="Use project scope")
    ] = False,
    format: Annotated[
        Optional[str],
        typer.Option("--format", "-f", help="Output format: json")
    ] = None,
    quiet: Annotated[
        bool,
        typer.Option("--quiet", "-q", help="Suppress non-essential output")
    ] = False,
):
    """Generate a summary of the knowledge graph.

    Without a topic argument, summarizes the entire knowledge graph.
    With a topic, generates a focused summary about that specific topic.

    Examples:
        graphiti summarize
        graphiti summarize "architecture decisions"
        graphiti summarize "llm integration" --format json
    """
    try:
        # Resolve scope
        scope, _ = resolve_scope(global_scope, project_scope)

        # Determine mode and set up spinner
        if topic is None:
            # Whole-graph summary
            status_msg = "Summarizing knowledge graph..."
        else:
            # Topic-focused summary
            status_msg = f"Summarizing knowledge about '{topic}'..."

        # Show spinner while loading and generating
        with console.status(status_msg) as status:
            # Load entities
            entities = _load_entities(scope, topic)

            # Update spinner with count
            if topic is None and len(entities) > 0:
                status.update(f"Summarizing {len(entities)} entities...")

            # Check if any entities found
            if not entities:
                if topic is None:
                    print_warning("No knowledge found to summarize.")
                else:
                    print_warning(f"No knowledge found about '{topic}'.")
                raise typer.Exit(0)

            # Generate summary via LLM
            summary_text = _generate_summary(entities, topic)

        # Output results
        if format == "json":
            print_json({
                "summary": summary_text,
                "scope": scope.value,
                "topic": topic,
                "entity_count": len(entities),
            })
        else:
            # Rich panel display
            title = f"Knowledge Summary{' - ' + topic if topic else ''}"
            panel = Panel(
                Markdown(summary_text),
                title=title,
                border_style="cyan",
                padding=(1, 2),
            )
            console.print(panel)

            if not quiet:
                console.print(f"\n[dim]Summarized {len(entities)} entities from {scope.value} graph[/dim]")

    except LLMUnavailableError:
        print_error(
            "LLM unavailable. Cannot generate summary.",
            suggestion="Run 'graphiti health' for diagnostics."
        )
        raise typer.Exit(EXIT_ERROR)
    except Exception as e:
        print_error(f"Failed to generate summary: {str(e)}")
        raise typer.Exit(EXIT_ERROR)
