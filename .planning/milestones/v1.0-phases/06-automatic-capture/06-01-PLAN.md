---
phase: 06-automatic-capture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/capture/__init__.py
  - src/capture/git_capture.py
  - src/capture/batching.py
  - src/capture/relevance.py
  - src/capture/summarizer.py
autonomous: true

must_haves:
  truths:
    - "Pending commits file can be read and cleared atomically without losing concurrent appends"
    - "Git show output for a commit is fetched with per-file truncation at 500 lines"
    - "Batch accumulator groups items into batches of 10 and supports partial flush"
    - "Relevance filter identifies decisions/architecture/bugs/dependencies and excludes WIP/routine content"
    - "LLM summarizer produces a single session summary from a batch of commit diffs"
    - "Security filtering runs on raw content BEFORE LLM summarization"
  artifacts:
    - path: "src/capture/__init__.py"
      provides: "Module exports for capture pipeline"
      exports: ["read_and_clear_pending_commits", "fetch_commit_diff", "BatchAccumulator", "filter_relevant_commit", "summarize_batch"]
    - path: "src/capture/git_capture.py"
      provides: "Git commit data extraction and pending file I/O"
      contains: "read_and_clear_pending_commits"
    - path: "src/capture/batching.py"
      provides: "Batch accumulator for grouping items before processing"
      contains: "class BatchAccumulator"
    - path: "src/capture/relevance.py"
      provides: "Content relevance filtering for capture"
      contains: "RELEVANCE_CATEGORIES"
    - path: "src/capture/summarizer.py"
      provides: "LLM-powered batch summarization"
      contains: "summarize_batch"
  key_links:
    - from: "src/capture/summarizer.py"
      to: "src/security/sanitizer.py"
      via: "sanitize_content() called before LLM"
      pattern: "from src\\.security import sanitize_content"
    - from: "src/capture/summarizer.py"
      to: "src/llm"
      via: "LLM chat for summarization"
      pattern: "from src\\.llm import"
    - from: "src/capture/git_capture.py"
      to: "subprocess"
      via: "git show command execution"
      pattern: "subprocess\\.run.*git show"
---

<objective>
Build the capture pipeline core: git commit data extraction, batch accumulation, relevance filtering, and LLM-powered summarization. These are the foundational modules that all capture operations (git hooks, conversation capture) depend on.

Purpose: Provides the data processing pipeline that transforms raw git diffs and conversation transcripts into clean, relevant knowledge graph entities via LLM summarization.
Output: `src/capture/` package with git_capture.py, batching.py, relevance.py, summarizer.py
</objective>

<execution_context>
@/home/tasostilsi/.claude/get-shit-done/workflows/execute-plan.md
@/home/tasostilsi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-automatic-capture/06-CONTEXT.md
@.planning/phases/06-automatic-capture/06-RESEARCH.md
@src/security/__init__.py
@src/security/sanitizer.py
@src/llm/__init__.py
@src/queue/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create git capture and batch accumulator modules</name>
  <files>
    src/capture/__init__.py
    src/capture/git_capture.py
    src/capture/batching.py
  </files>
  <action>
Create the `src/capture/` package with three files:

**src/capture/git_capture.py** - Git commit data extraction:
- `read_and_clear_pending_commits(pending_file: Path) -> list[str]`: Atomically read and clear pending commits file. Use atomic rename pattern: `pending_file.rename(pending_file.with_suffix('.processing'))`, read the processing file, then `unlink()` it. Handle FileNotFoundError race gracefully (return empty list). Filter out empty lines. The pending_file default should be `Path.home() / ".graphiti" / "pending_commits"`.
- `fetch_commit_diff(commit_sha: str, repo_path: Path | None = None, max_lines_per_file: int = 500) -> str`: Run `git show --format=fuller --stat {commit_sha}` via subprocess to get metadata+stats, then run `git diff-tree --no-commit-id --patch {commit_sha}` and truncate each file's diff at `max_lines_per_file` lines. Use the awk-based truncation approach from research: track line count per `diff --git` section, print `"... (truncated at N lines)"` when exceeded. If repo_path provided, set cwd for subprocess. Return combined output string. For merge commits, use `git show -m --format=fuller --stat {commit_sha}` to show diff against each parent.
- `append_pending_commit(commit_sha: str, pending_file: Path | None = None) -> None`: Append commit hash to pending file (used for testing/manual queueing). Ensure parent directory exists with `mkdir(parents=True, exist_ok=True)`.

Use `subprocess.run()` with `capture_output=True, text=True, timeout=30`. Log errors via structlog. Do NOT catch subprocess errors silently -- let CalledProcessError propagate for debugging.

**src/capture/batching.py** - Batch accumulator:
- `class BatchAccumulator`: Generic batch accumulator that groups items until batch_size reached.
  - `__init__(self, batch_size: int = 10)`: Default batch of 10 per user decision.
  - `add(self, item: Any) -> list | None`: Add item. Returns full batch list when batch_size reached, None otherwise. Clears internal list after returning batch.
  - `flush(self) -> list`: Force-flush partial batch (for shutdown/timeout). Returns current items and clears.
  - `__len__(self) -> int`: Current item count.
  - `is_empty(self) -> bool`: Whether accumulator has items.

**src/capture/__init__.py** - Package exports:
- Export: `read_and_clear_pending_commits`, `fetch_commit_diff`, `append_pending_commit`, `BatchAccumulator`
- Will be extended in Task 2 with relevance and summarizer exports.
  </action>
  <verify>
Run: `python -c "from src.capture import read_and_clear_pending_commits, fetch_commit_diff, append_pending_commit, BatchAccumulator; b = BatchAccumulator(3); assert b.add(1) is None; assert b.add(2) is None; result = b.add(3); assert result == [1,2,3]; assert len(b) == 0; print('OK')"` -- should print OK.
Run: `python -c "from src.capture.git_capture import fetch_commit_diff; diff = fetch_commit_diff('HEAD'); print(diff[:200] if diff else 'empty'); print('OK')"` -- should print commit info then OK.
  </verify>
  <done>
git_capture.py has read_and_clear_pending_commits (atomic rename pattern), fetch_commit_diff (subprocess with per-file truncation at 500 lines), and append_pending_commit. BatchAccumulator accumulates items and returns full batches at size 10 (configurable). Package __init__.py exports all public names.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create relevance filter and LLM summarizer modules</name>
  <files>
    src/capture/relevance.py
    src/capture/summarizer.py
    src/capture/__init__.py
  </files>
  <action>
**src/capture/relevance.py** - Content relevance filtering:
- `RELEVANCE_CATEGORIES` dict mapping category name to list of keyword indicators:
  - `"decisions"`: ["decided", "chose", "selected", "alternative", "option", "rejected", "tradeoff", "instead of", "rather than"]
  - `"architecture"`: ["design", "structure", "pattern", "component", "interface", "layer", "module", "refactor", "architecture"]
  - `"bugs"`: ["fix", "bug", "error", "issue", "crash", "regression", "root cause", "workaround", "patch"]
  - `"dependencies"`: ["add", "install", "upgrade", "remove", "dependency", "library", "package", "version", "migrate"]
- `EXCLUDE_PATTERNS` list of compiled regex patterns for content to skip:
  - `r"\bfixup!\b"`, `r"\bwip\b"`, `r"\btypo\s"`, `r"^(format|formatted)\b"`, `r"^ran tests?\b"`, `r"^update[d]?\s+readme\b"`, `r"\bsquash!\b"`, `r"^lint\b"`, `r"^chore:\s*(format|lint)"`, `r"\btemporary\b.*\bexperiment\b"`, `r"\bdebugging\b.*\btrace\b"`
- `DEFAULT_CATEGORIES` = list of all 4 category keys (full set by default per user decision)
- `filter_relevant_commit(commit_message: str, categories: list[str] | None = None) -> bool`: Check if commit message matches any enabled category keywords AND doesn't match any exclude pattern. categories defaults to DEFAULT_CATEGORIES. Returns True if relevant (at least one category match and no exclude match), False otherwise. Case-insensitive matching.
- `get_active_categories(config_categories: list[str] | None = None) -> list[str]`: Returns configured categories or DEFAULT_CATEGORIES. Validates that requested categories exist in RELEVANCE_CATEGORIES.

**src/capture/summarizer.py** - LLM batch summarization:
- `BATCH_SUMMARIZATION_PROMPT` template string (from research) with placeholders for source, count, items, content. Focus on extracting: Decisions and rationale, Architecture and patterns, Bug fixes and root causes, Dependencies and config. Explicit EXCLUDE section: raw code snippets, routine operations, WIP/scratch content. Add deduplication instruction for merge commits: "If merge commit content overlaps with individual commits in this batch, skip redundant information."
- `async def summarize_batch(content_items: list[str], source: str = "git commits", item_label: str = "commits") -> str`: Takes list of content strings (e.g., git diffs), joins them with separators, formats the BATCH_SUMMARIZATION_PROMPT, runs Phase 2 security filter (`sanitize_content()`) on the joined content BEFORE sending to LLM (per locked decision: security gate before LLM), then calls `src.llm.chat()` with the prompt. Returns the LLM response text. If LLMUnavailableError, log warning and return a basic concatenation of content items (graceful fallback, matches Phase 4 summarize pattern). Import `sanitize_content` from `src.security` and `chat` from `src.llm`.
- `async def summarize_and_store(content_items: list[str], source: str, scope: GraphScope, project_root: Path | None = None, tags: list[str] | None = None) -> dict | None`: High-level function that calls `summarize_batch()`, then uses `src.graph.get_service()` + `run_graph_operation()` to store the summary via `service.add()`. Returns the stored entity dict or None on failure. Tags should default to `["auto-capture", source]`. This function bridges capture -> storage.

**Update src/capture/__init__.py** to add exports:
- Add: `filter_relevant_commit`, `get_active_categories`, `RELEVANCE_CATEGORIES`, `DEFAULT_CATEGORIES`, `summarize_batch`, `summarize_and_store`
  </action>
  <verify>
Run: `python -c "from src.capture.relevance import filter_relevant_commit, RELEVANCE_CATEGORIES, DEFAULT_CATEGORIES; assert filter_relevant_commit('feat: decided to use Redis instead of Memcached'); assert not filter_relevant_commit('fixup! typo in readme'); assert not filter_relevant_commit('wip scratch stuff'); assert filter_relevant_commit('fix: crash on null pointer in parser'); print('OK')"` -- should print OK.
Run: `python -c "from src.capture.summarizer import BATCH_SUMMARIZATION_PROMPT; assert 'Decisions' in BATCH_SUMMARIZATION_PROMPT; assert 'EXCLUDE' in BATCH_SUMMARIZATION_PROMPT; assert 'security' not in BATCH_SUMMARIZATION_PROMPT.lower() or 'sanitize' in BATCH_SUMMARIZATION_PROMPT.lower(); print('OK')"` -- prompt template exists with required sections.
Run: `python -c "from src.capture import filter_relevant_commit, summarize_batch; print('All exports OK')"` -- package exports work.
  </verify>
  <done>
relevance.py has RELEVANCE_CATEGORIES with 4 category keyword lists, EXCLUDE_PATTERNS for WIP/routine/scratch content, filter_relevant_commit() for checking commit relevance, and get_active_categories() for config-driven category selection. summarizer.py has BATCH_SUMMARIZATION_PROMPT with extraction/exclusion instructions and merge deduplication, summarize_batch() that security-filters content THEN calls LLM, and summarize_and_store() that bridges capture to graph storage. All exports added to __init__.py.
  </done>
</task>

</tasks>

<verification>
1. `python -c "import src.capture; print(dir(src.capture))"` -- shows all expected exports
2. `python -c "from src.capture.git_capture import read_and_clear_pending_commits, fetch_commit_diff; print('git_capture OK')"` -- git capture module loads
3. `python -c "from src.capture.batching import BatchAccumulator; b = BatchAccumulator(2); assert b.add('a') is None; assert b.add('b') == ['a','b']; print('batching OK')"` -- batch accumulator works
4. `python -c "from src.capture.relevance import filter_relevant_commit; assert filter_relevant_commit('Added new dependency: redis'); assert not filter_relevant_commit('fixup! typo'); print('relevance OK')"` -- relevance filtering works
5. `python -c "from src.capture.summarizer import summarize_batch, BATCH_SUMMARIZATION_PROMPT; print('summarizer OK')"` -- summarizer module loads
</verification>

<success_criteria>
- src/capture/ package exists with 5 files (init, git_capture, batching, relevance, summarizer)
- Atomic pending file read-and-clear uses rename pattern (not read+truncate)
- Per-file diff truncation at 500 lines (Claude's discretion from user decision)
- Batch accumulator defaults to size 10 (locked user decision)
- All 4 relevance categories implemented with keyword lists
- Exclude patterns cover WIP, fixup, routine, scratch content
- Summarizer calls sanitize_content() BEFORE LLM (locked security gate decision)
- Summarizer prompt includes merge deduplication instruction
- LLM fallback returns basic content on LLMUnavailableError
</success_criteria>

<output>
After completion, create `.planning/phases/06-automatic-capture/06-01-SUMMARY.md`
</output>
