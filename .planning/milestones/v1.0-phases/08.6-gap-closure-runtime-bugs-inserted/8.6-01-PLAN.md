---
phase: 8.6-gap-closure-runtime-bugs-inserted
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/graph/adapters.py
autonomous: true
gap_closure: true
requirements:
  - R4.1
  - R4.2

must_haves:
  truths:
    - "process_pending_commits() stores at least one entity when commits touch dot-prefixed files"
    - "LLM response field names with leading dots are normalized before Pydantic validation"
    - "No 'Field required' ValidationError for extracted_entities[N].name when filename starts with '.'"
  artifacts:
    - path: "src/graph/adapters.py"
      provides: "_normalize_field_names() helper that strips leading dots from JSON keys"
      contains: "_normalize_field_names"
  key_links:
    - from: "src/graph/adapters.py"
      to: "_generate_response"
      via: "_normalize_field_names called before Pydantic parse"
      pattern: "_normalize_field_names"
---

<objective>
Fix LLM output parsing failure where cloud models return `".name"` (dot-prefixed key) instead of `"name"` when processing diff content that contains dot-prefixed filenames (e.g., `.env.test_verification`).

**Root cause**: The cloud LLM (`glm-5`/`kimi-k2.5` on ollama.com) occasionally mirrors the dot prefix from filenames in the content it's summarizing into the JSON field names it generates. This produces `{".name": "value"}` instead of `{"name": "value"}`, failing Pydantic's required-field validation.

**Error observed (2026-02-26)**:
```
1 validation error for ExtractedEntities
extracted_entities.5.name
  Field required [type=missing, input_value={'.name': '.env.test_veri...n', 'entity_type_id': 0}]
```

**Fix**: Add a `_normalize_field_names(data)` recursive helper in `OllamaLLMClient` that strips leading dots from dict keys before the JSON is passed to Pydantic. Call it inside `_generate_response()` after JSON parsing and before `response_model.model_validate()`.

Output: `src/graph/adapters.py` with normalization applied; `process_pending_commits()` no longer drops all entities due to one malformed field name.
</objective>

<execution_context>
@/home/tasostilsi/.claude/get-shit-done/workflows/execute-plan.md
@/home/tasostilsi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add _normalize_field_names() and call it before Pydantic validation</name>
  <files>src/graph/adapters.py</files>
  <action>
Read `src/graph/adapters.py` fully first to locate:
- The `OllamaLLMClient` class
- The `_generate_response()` method
- The section where `response_text` is parsed as JSON and then passed to `response_model.model_validate()`

**Step 1 — Add the helper method** to `OllamaLLMClient`, alongside the other `_strip_schema_suffix`, `_inject_example` helpers:

```python
@staticmethod
def _normalize_field_names(data: Any) -> Any:
    """Recursively strip leading dots from dict keys in LLM JSON output.

    Some cloud models mirror dot-prefixed filenames from content into
    field names, producing {".name": "value"} instead of {"name": "value"}.
    This normalizes keys before Pydantic validation to prevent spurious
    'Field required' errors.

    Args:
        data: Parsed JSON value (dict, list, or scalar)

    Returns:
        Same structure with leading dots stripped from all dict keys
    """
    if isinstance(data, dict):
        return {
            k.lstrip("."): OllamaLLMClient._normalize_field_names(v)
            for k, v in data.items()
        }
    if isinstance(data, list):
        return [OllamaLLMClient._normalize_field_names(item) for item in data]
    return data
```

**Step 2 — Call it** in `_generate_response()` just before `response_model.model_validate(parsed)`. Find the block that looks like:

```python
parsed = json.loads(clean_text)
# ... possibly list-wrapping logic ...
return response_model.model_validate(parsed).model_dump()
```

Insert the normalization call immediately before `model_validate`:

```python
parsed = self._normalize_field_names(parsed)
return response_model.model_validate(parsed).model_dump()
```

If there are multiple `model_validate` call sites in `_generate_response()` (e.g., inside the list-wrapping fallback block), apply `_normalize_field_names` before each one.

Do NOT change any other logic — the strip/inject/retry flow remains intact.
  </action>
  <verify>
```bash
# Helper exists
grep -n "_normalize_field_names" src/graph/adapters.py

# Called before model_validate
grep -n -A2 "_normalize_field_names\|model_validate" src/graph/adapters.py | head -30

# Module imports cleanly
.venv/bin/python -c "from src.graph.adapters import OllamaLLMClient; print('ok')"
```
Expected: `_normalize_field_names` appears as definition + at least one call site immediately before `model_validate`. Module imports without error.
  </verify>
  <done>
`src/graph/adapters.py` contains `_normalize_field_names()` static method and it is called before every `response_model.model_validate()` in `_generate_response()`. Module imports cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Smoke-test the fix with a synthetic malformed LLM response</name>
  <files>src/graph/adapters.py</files>
  <action>
Run a quick inline Python test to verify the normalization works for the exact payload that failed:

```bash
.venv/bin/python3 -c "
from src.graph.adapters import OllamaLLMClient

# Simulate the malformed LLM output that caused the real failure
malformed = {
    'extracted_entities': [
        {'name': 'Git Hook', 'entity_type_id': 0},
        {'name': 'Graphiti', 'entity_type_id': 0},
        {'.name': '.env.test_verification', 'entity_type_id': 0},  # <-- the bug
    ]
}

normalized = OllamaLLMClient._normalize_field_names(malformed)
entity = normalized['extracted_entities'][2]
assert 'name' in entity, f'Expected name key, got: {list(entity.keys())}'
assert '.name' not in entity, f'Dot key still present'
assert entity['name'] == '.env.test_verification', f'Value changed: {entity[\"name\"]}'
print('PASS: .name -> name, value preserved:', entity['name'])
"
```

This must print `PASS`.
  </action>
  <verify>
Script exits 0 and prints `PASS: .name -> name, value preserved: .env.test_verification`.
  </verify>
  <done>
Inline test passes — normalization correctly strips the leading dot from the key while preserving the value.
  </done>
</task>

</tasks>

<verification>
1. Helper defined and called:
   ```bash
   grep -c "_normalize_field_names" src/graph/adapters.py
   ```
   Expected: >= 2 (definition + at least one call)

2. Module clean:
   ```bash
   .venv/bin/python -c "from src.graph.adapters import OllamaLLMClient; print('ok')"
   ```

3. Smoke test passes (from Task 2 above).

4. Commit the fix:
   ```bash
   git add src/graph/adapters.py
   git commit -m "fix: normalize dot-prefixed field names in LLM JSON output before Pydantic validation"
   ```
</verification>

<success_criteria>
- `_normalize_field_names()` strips leading dots from all dict keys recursively
- Called before every `model_validate()` in `_generate_response()`
- Smoke test passes for the exact payload shape that caused the 2026-02-26 failure
- `process_pending_commits()` will no longer drop entire batches due to one entity with a dot-prefixed filename
</success_criteria>

<output>
After completion, create `.planning/phases/08.6-gap-closure-runtime-bugs-inserted/8.6-01-SUMMARY.md` following the GSD summary template.
</output>
