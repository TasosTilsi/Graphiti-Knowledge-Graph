---
phase: 07-git-integration
plan: 03
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/gitops/checkpoint.py
  - src/gitops/replay.py
autonomous: true

must_haves:
  truths:
    - "Checkpoint file tracks the last-applied journal entry filename"
    - "Checkpoint updates are atomic (write-to-temp, rename) to prevent corruption"
    - "Incremental replay only processes journal entries after the checkpoint"
    - "Last-write-wins resolution handles entity-level conflicts by timestamp ordering"
    - "Full rebuild from journal recreates database from scratch when needed"
  artifacts:
    - path: "src/gitops/checkpoint.py"
      provides: "Checkpoint file management with atomic read/write"
      exports: ["get_checkpoint", "set_checkpoint", "get_new_journal_entries"]
    - path: "src/gitops/replay.py"
      provides: "Journal replay engine with incremental and full rebuild modes"
      exports: ["replay_journal", "rebuild_from_journal", "JournalReplayer"]
  key_links:
    - from: "src/gitops/checkpoint.py"
      to: ".graphiti/checkpoint"
      via: "atomic file write"
      pattern: "replace.*checkpoint"
    - from: "src/gitops/replay.py"
      to: "src/gitops/checkpoint.py"
      via: "checkpoint update after each entry"
      pattern: "set_checkpoint"
    - from: "src/gitops/replay.py"
      to: "src/gitops/journal.py"
      via: "reads journal entries"
      pattern: "list_journal_entries|get_new_journal_entries"
---

<objective>
Build checkpoint tracking and journal replay engine for incremental database synchronization.

Purpose: The checkpoint system enables fast incremental replay (only process new entries since last sync) instead of full rebuild every time. This is critical for post-merge auto-heal performance and multi-developer workflows where each developer's local DB must stay in sync with the shared journal.

Output: Atomic checkpoint management and journal replay with last-write-wins conflict resolution.
</objective>

<execution_context>
@/home/tasostilsi/.claude/get-shit-done/workflows/execute-plan.md
@/home/tasostilsi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-git-integration/07-CONTEXT.md
@.planning/phases/07-git-integration/07-RESEARCH.md
@.planning/phases/07-git-integration/07-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create checkpoint manager with atomic updates</name>
  <files>src/gitops/checkpoint.py</files>
  <action>
    Create `src/gitops/checkpoint.py` with:

    **get_checkpoint(project_root: Path) -> str | None:**
    - Read `.graphiti/checkpoint` file in project_root
    - Return filename string (single line, stripped) if exists
    - Return None if file doesn't exist
    - Handle read errors gracefully (return None)

    **set_checkpoint(project_root: Path, filename: str) -> None:**
    - Use atomic write pattern: write to `.graphiti/checkpoint.tmp`, then `Path.replace()` to `.graphiti/checkpoint`
    - `Path.replace()` is atomic on POSIX systems (per research)
    - Create `.graphiti/` directory if needed
    - Log checkpoint update via structlog

    **clear_checkpoint(project_root: Path) -> None:**
    - Remove `.graphiti/checkpoint` file if it exists
    - Used for full rebuild scenarios

    **get_new_journal_entries(project_root: Path) -> list[Path]:**
    - Get checkpoint via get_checkpoint()
    - Get all journal entries via `sorted(journal_dir.glob("*.json"))` (same as list_journal_entries)
    - If checkpoint exists: find its position in sorted list, return entries after it
    - If no checkpoint: return all entries (first-time setup)
    - Return empty list if journal directory doesn't exist

    **validate_checkpoint(project_root: Path) -> bool:**
    - Get checkpoint value
    - If None, return True (no checkpoint = valid state)
    - Check if the referenced journal entry file actually exists
    - Return True if file exists, False if orphaned checkpoint (points to deleted entry)
    - Used by health check to detect corruption

    Use structlog for logging (consistent with project pattern).
  </action>
  <verify>
    ```bash
    cd /home/tasostilsi/Development/Projects/graphiti-knowledge-graph
    python -c "
    from src.gitops.checkpoint import get_checkpoint, set_checkpoint, get_new_journal_entries, validate_checkpoint, clear_checkpoint
    from src.gitops.journal import create_journal_entry, JournalOperation
    from pathlib import Path
    import tempfile, time

    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)

        # No checkpoint initially
        assert get_checkpoint(root) is None
        assert validate_checkpoint(root) == True

        # Create some journal entries
        e1 = create_journal_entry(JournalOperation.ADD_ENTITY, {'name': 'A'}, project_root=root)
        time.sleep(0.01)
        e2 = create_journal_entry(JournalOperation.ADD_ENTITY, {'name': 'B'}, project_root=root)
        time.sleep(0.01)
        e3 = create_journal_entry(JournalOperation.ADD_ENTITY, {'name': 'C'}, project_root=root)

        # All entries are new (no checkpoint)
        new = get_new_journal_entries(root)
        assert len(new) == 3

        # Set checkpoint to first entry
        set_checkpoint(root, e1.name)
        assert get_checkpoint(root) == e1.name
        assert validate_checkpoint(root) == True

        # Now only entries after e1 are new
        new = get_new_journal_entries(root)
        assert len(new) == 2
        assert new[0].name == e2.name

        # Set to second entry
        set_checkpoint(root, e2.name)
        new = get_new_journal_entries(root)
        assert len(new) == 1
        assert new[0].name == e3.name

        # Clear checkpoint
        clear_checkpoint(root)
        assert get_checkpoint(root) is None

        print('Checkpoint manager OK')
    "
    ```
  </verify>
  <done>Checkpoint manager reads/writes atomically, get_new_journal_entries correctly returns only entries after checkpoint, and validate_checkpoint detects orphaned references.</done>
</task>

<task type="auto">
  <name>Task 2: Create journal replay engine with last-write-wins</name>
  <files>src/gitops/replay.py, src/gitops/__init__.py</files>
  <action>
    Create `src/gitops/replay.py` with:

    **JournalReplayer class:**
    - `__init__(self, project_root: Path)`: Store project_root, initialize structlog logger
    - This class encapsulates replay logic. For now, it processes journal entries and applies them conceptually. The actual Kuzu DB application will be wired when the capture pipeline integration is complete. The replayer establishes the control flow and checkpoint management.

    **replay_journal(self) -> int:**
    - Get new journal entries via get_new_journal_entries(self.project_root)
    - If none, log "No new journal entries" and return 0
    - For each entry:
      1. Read and parse JSON
      2. Validate against JournalEntry model (skip invalid entries with warning)
      3. Call `self._apply_entry(entry_data)` to process
      4. Call `set_checkpoint(self.project_root, entry_file.name)` after EACH entry (not batch - per research pitfall #4)
    - Return count of applied entries
    - Log summary: "Replayed N journal entries"

    **_apply_entry(self, entry: dict) -> bool:**
    - Parse operation type from entry
    - For now, log the operation (actual DB application will be connected via a callback/hook pattern):
      - Store a list of applied operations for inspection
      - The replayer accepts an optional `apply_fn: Callable[[dict], bool]` in __init__ that processes each entry
      - If no apply_fn provided, just track entries (useful for testing and dry-run)
    - Return True on success, False on failure
    - Last-write-wins is inherent: entries are processed in timestamp order (sorted filenames), so later operations naturally overwrite earlier ones for the same entity

    **rebuild_from_journal(self) -> int:**
    - Clear checkpoint via clear_checkpoint()
    - Call replay_journal() to process all entries from beginning
    - Return count of entries applied
    - This is the full rebuild path used when LFS unavailable or DB corrupted

    **Module-level convenience functions:**
    - `replay_journal(project_root, apply_fn=None) -> int`: Create JournalReplayer and call replay_journal()
    - `rebuild_from_journal(project_root, apply_fn=None) -> int`: Create JournalReplayer and call rebuild_from_journal()

    Update `src/gitops/__init__.py` to export checkpoint and replay functions:
    - get_checkpoint, set_checkpoint, get_new_journal_entries, validate_checkpoint
    - replay_journal, rebuild_from_journal, JournalReplayer
  </action>
  <verify>
    ```bash
    cd /home/tasostilsi/Development/Projects/graphiti-knowledge-graph
    python -c "
    from src.gitops.replay import JournalReplayer, replay_journal, rebuild_from_journal
    from src.gitops.journal import create_journal_entry, JournalOperation
    from src.gitops.checkpoint import get_checkpoint
    from pathlib import Path
    import tempfile, time

    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)

        # Create journal entries
        create_journal_entry(JournalOperation.ADD_ENTITY, {'name': 'Entity1'}, project_root=root)
        time.sleep(0.01)
        create_journal_entry(JournalOperation.ADD_ENTITY, {'name': 'Entity2'}, project_root=root)
        time.sleep(0.01)
        create_journal_entry(JournalOperation.UPDATE_ENTITY, {'name': 'Entity1', 'summary': 'Updated'}, project_root=root)

        # Track applied entries
        applied = []
        def track_fn(entry):
            applied.append(entry)
            return True

        # Replay all entries
        replayer = JournalReplayer(root, apply_fn=track_fn)
        count = replayer.replay_journal()
        assert count == 3
        assert len(applied) == 3

        # Checkpoint should point to last entry
        checkpoint = get_checkpoint(root)
        assert checkpoint is not None

        # Replay again - no new entries
        applied.clear()
        count = replayer.replay_journal()
        assert count == 0

        # Add one more entry
        create_journal_entry(JournalOperation.DELETE_ENTITY, {'name': 'Entity2'}, project_root=root)
        count = replayer.replay_journal()
        assert count == 1

        # Test full rebuild
        applied.clear()
        count = replayer.rebuild_from_journal()
        assert count == 4  # All entries replayed

        # Test convenience functions
        count = replay_journal(root)
        assert count == 0  # Already at latest checkpoint

        print('Replay engine OK')
    "
    ```
  </verify>
  <done>JournalReplayer processes entries in chronological order with per-entry checkpoint updates. Incremental replay skips already-applied entries. Full rebuild clears checkpoint and replays all. Last-write-wins is achieved by timestamp ordering.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.gitops import replay_journal, rebuild_from_journal, get_checkpoint"` succeeds
2. Checkpoint updates atomically after each entry (not in batch)
3. Incremental replay correctly skips already-processed entries
4. Full rebuild replays all entries from beginning
5. Invalid journal entries are skipped with warnings, not crashes
</verification>

<success_criteria>
- Checkpoint file tracks last-applied entry with atomic writes
- get_new_journal_entries returns only unprocessed entries
- Journal replay processes entries in chronological (timestamp) order
- Per-entry checkpoint prevents duplicate processing on crash
- Full rebuild from journal works as LFS fallback
- Convenience functions provide simple API for hooks
</success_criteria>

<output>
After completion, create `.planning/phases/07-git-integration/07-03-SUMMARY.md`
</output>
