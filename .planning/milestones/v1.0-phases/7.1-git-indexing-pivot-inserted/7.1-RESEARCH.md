# Phase 7.1: Git Indexing Pivot [INSERTED] - Research

**Researched:** 2026-02-20
**Domain:** Git history traversal, incremental indexing, SHA deduplication, background subprocess hooks, LLM extraction pipelines
**Confidence:** HIGH

---

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

**What gets removed from Phase 7:**
- Journal entry Pydantic model and timestamped file writer (`src/gitops/journal.py`) — 07-01
- LFS helpers and journal-specific `.gitattributes` entries (`src/gitops/lfs.py`, `src/gitops/config.py` LFS parts) — 07-02
- Checkpoint tracking and incremental replay engine (`src/gitops/checkpoint.py`, `src/gitops/replay.py`) — 07-03
- Journal-specific pre-commit hooks: staging and schema validation (`src/gitops/hooks.py` stage/validate functions) — 07-04
- Post-merge auto-heal, journal compaction, journal-specific hook templates (`src/gitops/autoheal.py`, `src/gitops/compact.py`, hook templates) — 07-05

**What stays from Phase 7:**
- Pre-commit secrets scanning — still valuable, prevents secrets in any committed file
- Pre-commit size checks — still useful for general repo health
- `.gitignore` entry for `.graphiti/` — DB stays local (already in root `.gitignore`)
- Git hook installer framework (`src/hooks/installer.py`, `src/hooks/manager.py`) — repurposed for new indexer hooks

**Phase 6 + indexer relationship (no duplication):**
- Indexer = historical bootstrap (brownfield projects) — processes past commits up to current HEAD
- Phase 6 post-commit hook = ongoing real-time capture — captures every new commit going forward
- SHA-based deduplication: indexer tracks processed commit SHAs; skips any commit already in Kuzu
- `graphiti index --full`: wipes all git-indexed knowledge and re-processes entire history from scratch — Phase 6 captures are NOT affected
- Greenfield projects: Phase 6 handles everything from commit #1 — indexer not needed but harmless

**Index extraction — Data sources per commit:**
- Commit messages
- Commit diffs (actual code changes)
- File-level change patterns (which files change together, churn signals)

**Quality gate — skip these commits entirely:**
- Version-bump-only commits (only change version numbers in package.json, pyproject.toml, `__version__`)
- Automated/bot commits (Dependabot, GitHub Actions, CI bots — detected by author email pattern or commit message prefix)
- Pure merge commits (no conflict resolution — empty diff beyond the merge)
- Tiny commits (1–3 lines changed) — typo fixes, whitespace, formatting

**Large diff handling:**
- Two-pass for commits above a size threshold:
  1. Fast LLM pass: summarize the diff
  2. Extraction pass: structured + free-form extraction on the summary

**Extraction strategy — two-pass per commit:**
1. Structured Q&A pass: LLM answers "What decision? What changed? Why? Files affected?"
2. Free-form entity extraction pass: LLM extracts entities and relationships freely
- Both passes merged into Kuzu via `graphiti.add_episode()`

**Index depth and scope:**
- Default: full git history from beginning
- Configurable via `index.max_commits` and `index.since` (date or SHA)
- Path scope: whole repository, users add exclusions via config

**`graphiti index` command modes:**
- `graphiti index` — incremental (default)
- `graphiti index --full` — wipe all git-indexed knowledge and re-process entire history
- `graphiti index --since <date or SHA>` — partial re-index window
- Progress: spinner + current commit message + completion summary (stats + top 3-5 findings)
- Interruption: resume from last processed SHA cursor

**Stale detection and auto-triggers:**
- Stale when: local HEAD has changed or remote has new commits not yet indexed
- Response: background re-index silently — never blocks the user
- Git hooks: post-merge, post-checkout, post-rewrite (NOT post-commit — that's Phase 6)
- Rate limiting: cooldown period (default 5 minutes) between auto-triggers

### Claude's Discretion
- Exact SHA cursor storage format (SQLite table, JSON file, or Kuzu metadata)
- Size threshold for triggering the two-pass large-diff summarization
- Exact author/email patterns used for bot commit detection
- Cooldown period storage and expiry mechanism

### Deferred Ideas (OUT OF SCOPE)
- None — discussion stayed within phase scope

</user_constraints>

---

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| R8.1 | Git-Safe Knowledge Graphs — REVISED: local-first indexing replaces git-sharing. `.graphiti/` fully gitignored, no committed graph files. | SHA deduplication + gitignore pattern ensures local-only storage; existing root `.gitignore` already excludes `.graphiti/` |
| R8.2 | Merge Conflict Prevention — REVISED: by going fully local, there are no graph files in git at all, so merge conflicts on graph data become impossible by design. | Fully gitignoring `.graphiti/` eliminates all conflict scenarios; no alternative storage format needed |

**Note on revised acceptance criteria:** R8.1 and R8.2 original acceptance criteria (committable graphs, CI checks, concurrent commit tests) are superseded. The new success criteria from the phase description apply: `graphiti index` builds Kuzu from git history, stale detection triggers background re-index, `.graphiti/` fully gitignored, background indexing non-blocking (<100ms hook overhead), journal/LFS components removed, secrets scanning and size checks preserved.

</phase_requirements>

---

## Summary

Phase 7.1 performs two parallel operations: a **surgical removal** of the journal-based architecture implemented in Phase 7 (07-01 through 07-05), and the **addition** of a new git history indexer. The removal is well-bounded — seven specific Python modules (`journal.py`, `lfs.py`, `checkpoint.py`, `replay.py`, `hooks.py` journal functions, `autoheal.py`, `compact.py`) plus related hook templates and CLI references. The addition is the main engineering challenge.

The indexer is built on top of the existing `capture/git_capture.py` infrastructure (already handles per-commit diff fetching via `fetch_commit_diff()`), the existing `graph/service.py` `add()` / `add_episode()` pipeline, and the existing `hooks/installer.py` framework. GitPython's `repo.iter_commits()` is the right tool for traversal — it is already a project dependency, provides SHA access, parent access, author metadata, and diff access. The key new components are: a SHA cursor store for deduplication and interruption resume, a quality-gate filter, a two-pass LLM extraction pipeline per commit, a new CLI `index` command, and three new git hook templates (post-merge, post-checkout, post-rewrite) that trigger background re-indexing.

The main design decision left to Claude's discretion is the SHA cursor storage format. Research strongly supports a **JSON file** at `.graphiti/index-state.json` as the simplest, most portable option for this phase — no new dependencies, human-readable, survives git operations, easy to wipe for `--full` resets. Cooldown tracking fits naturally in the same file (last-run timestamp). SQLite would be equally valid but adds complexity for what is essentially a small set of string keys.

**Primary recommendation:** Build the indexer as `src/indexer/` — a new module parallel to `src/capture/`, reusing `fetch_commit_diff()` and `summarize_and_store()` from Phase 6 where appropriate, with GitPython for history traversal and a JSON state file for cursor + cooldown tracking.

---

## Standard Stack

### Core

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| GitPython | >=3.1.0 (already in deps) | Traverse git history, access commit metadata, diffs, author info | Already a project dependency; `repo.iter_commits()` provides exact API needed; handles all commit metadata (SHA, parents, author, message, stats) |
| graphiti_core | 0.26.3 (already in deps) | Store extracted knowledge via `add_episode()` | Already the project's graph storage API; `EpisodeType.text` and `source_description` give correct tagging for git-sourced episodes |
| structlog | >=25.5.0 (already in deps) | Structured logging throughout indexer | Already project standard; consistent with all other modules |
| typer[all] | >=0.15.0 (already in deps) | `graphiti index` CLI command | Already project CLI framework; consistent with all 12 existing commands |
| Rich | (via typer[all], already in deps) | Spinner progress UI during indexing | Already project standard output library; `console.status()` pattern used in hooks.py |

### Supporting

| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| Python `json` (stdlib) | stdlib | SHA cursor state file, cooldown timestamp | Sufficient for small state file — no external dependency needed |
| Python `subprocess` (stdlib) | stdlib | Background re-index from git hook shell scripts | Already used in `lfs.py` and `hooks/manager.py`; `Popen` with `close_fds=True` for fire-and-forget |
| Python `re` (stdlib) | stdlib | Bot commit detection regex patterns | Already used in `capture/git_worker.py`; no new dependency needed |
| Python `sqlite3` (stdlib) | stdlib | Alternative cursor storage (Claude's discretion — NOT recommended for this phase) | Only consider if JSON file proves insufficient; adds complexity without benefit at this scale |
| detect-secrets | >=1.5.0 (already in deps) | Secret scanning in pre-commit hook (preserved from Phase 7) | Pre-existing; the `scan_journal_secrets()` function in `gitops/hooks.py` gets refactored to `scan_staged_secrets()` for general use |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| JSON file for SHA cursor | SQLite table | SQLite provides atomic writes and concurrent-safe reads; but for a single-writer local tool, JSON + atomic rename (`Path.replace()`) is sufficient and zero-dependency |
| JSON file for SHA cursor | Kuzu metadata table | Kuzu metadata is elegant (collocated with the graph data) but requires the DB to be open to update cursor, creating ordering constraints; plain file is simpler |
| GitPython `iter_commits()` | `subprocess git log` | Direct subprocess avoids GitPython overhead; but GitPython already in deps, provides typed objects (commit.hexsha, commit.author.email, commit.parents), and is more maintainable |
| Two-pass LLM extraction | Single-pass extraction | Single pass is simpler and cheaper; two-pass gives both guaranteed baseline structure AND catches unexpected signals; matches the locked decision |

**No new `pip install` required** — all needed libraries are already in `pyproject.toml` dependencies.

---

## Architecture Patterns

### Recommended Project Structure

```
src/
├── indexer/                    # NEW module for git history indexer
│   ├── __init__.py
│   ├── indexer.py              # Main GitIndexer class + index_commits() logic
│   ├── state.py                # SHA cursor + cooldown JSON state management
│   ├── quality_gate.py         # Commit skip-filters (bot, version-bump, tiny, merge)
│   └── extraction.py           # Two-pass LLM extraction per commit
├── gitops/                     # MODIFIED — remove journal/lfs/checkpoint/replay/autoheal/compact
│   ├── __init__.py             # MODIFIED — update exports to remove deleted modules
│   ├── config.py               # MODIFIED — remove LFS parts, keep .gitignore generation
│   └── hooks.py                # MODIFIED — remove journal-specific funcs, keep secrets+size
├── hooks/                      # KEPT — repurposed for indexer hooks
│   ├── installer.py            # KEPT unchanged
│   ├── manager.py              # KEPT unchanged
│   └── templates/
│       ├── post-commit.sh      # KEPT (Phase 6 territory)
│       ├── pre-commit.sh       # MODIFIED — remove journal staging/schema, keep secrets+size
│       ├── post-merge.sh       # REPLACED — journal replay → background graphiti index
│       ├── post-checkout.sh    # NEW — triggers background graphiti index on branch switch
│       └── post-rewrite.sh     # NEW — triggers background graphiti index on rebase/amend
└── cli/
    ├── __init__.py             # MODIFIED — add `index` command registration
    └── commands/
        ├── index.py            # NEW — graphiti index command with --full/--since flags
        └── compact.py          # MODIFIED — remove --journal flag and journal-specific code

.graphiti/
├── graphiti.kuzu               # Kuzu DB (already gitignored via root .gitignore)
├── index-state.json            # NEW — SHA cursor + cooldown state (gitignored)
└── audit.log                   # Existing audit log (gitignored)
```

### Pattern 1: GitPython History Traversal

**What:** Use `repo.iter_commits()` to walk git history from HEAD backwards, yielding commit objects with SHA, author, parents, message, and stats.

**When to use:** The main indexer loop — processes all commits or commits since a given SHA/date.

**Verified API (HIGH confidence — GitPython 3.1.46 official docs):**
```python
# Source: https://gitpython.readthedocs.io/en/stable/tutorial.html

import git
from pathlib import Path

repo = git.Repo(search_parent_directories=True)

# Iterate all commits (HEAD to initial, chronological traversal in reverse)
for commit in repo.iter_commits():
    sha = commit.hexsha          # 40-char SHA string
    short_sha = sha[:7]
    author_email = commit.author.email
    author_name = commit.author.name
    message = commit.message.strip()
    parents = commit.parents      # list; empty = initial commit; >1 = merge
    num_parents = len(parents)

    # Stats: files changed, insertions, deletions
    stats = commit.stats         # commit.stats.total = {'files': N, 'insertions': N, ...}
    total_lines = (
        commit.stats.total.get('insertions', 0) +
        commit.stats.total.get('deletions', 0)
    )

# Filter by date (since parameter accepts datetime or ISO string)
for commit in repo.iter_commits(since="2025-01-01"):
    ...

# Filter by count
for commit in repo.iter_commits(max_count=100):
    ...

# Get all commits across all branches
for commit in repo.iter_commits(all=True):
    ...
```

**Getting diffs (for large diff detection and content extraction):**
```python
# Source: https://gitpython.readthedocs.io/en/stable/tutorial.html
# For a commit with one parent:
if commit.parents:
    diffs = commit.parents[0].diff(commit, create_patch=True)
    for d in diffs:
        patch_text = d.diff.decode('utf-8', errors='replace')  # actual unified diff
        a_path = d.a_path   # file before
        b_path = d.b_path   # file after
```

**Note on performance:** `iter_commits()` is lazy — it does not fetch diffs until `diff()` is called. Stats are also lazy. For large repos, only call `diff()` on commits that pass the quality gate to avoid unnecessary I/O.

### Pattern 2: SHA Cursor State File (Claude's Discretion — Recommended: JSON)

**What:** A local JSON file at `.graphiti/index-state.json` tracks: the set of processed SHAs (for deduplication), the last-processed SHA (for resumption), and the last-run timestamp (for cooldown).

**Why JSON over SQLite:** This phase has a single writer (the indexer process), small data volume (143 commits in this repo), and no concurrent reads. JSON with atomic rename satisfies all requirements with zero new dependencies.

**Recommended schema:**
```python
# .graphiti/index-state.json
{
    "version": "1.0",
    "last_indexed_sha": "abc123...",        # last SHA processed (cursor for resumption)
    "processed_shas": ["sha1", "sha2"],     # set of all indexed SHAs (deduplication)
    "last_run_at": "2026-02-20T10:00:00Z",  # ISO timestamp (cooldown check)
    "source": "graphiti-index",
    "indexed_commits_count": 42
}
```

**Atomic write pattern (from existing `checkpoint.py` — proven in this codebase):**
```python
# Source: existing src/gitops/checkpoint.py atomic write pattern
import json
from pathlib import Path
from datetime import datetime, timezone

STATE_FILE = ".graphiti/index-state.json"

def load_state(project_root: Path) -> dict:
    state_file = project_root / STATE_FILE
    if not state_file.exists():
        return {"version": "1.0", "processed_shas": [], "last_indexed_sha": None, "last_run_at": None}
    return json.loads(state_file.read_text())

def save_state(project_root: Path, state: dict) -> None:
    state_file = project_root / STATE_FILE
    state_file.parent.mkdir(parents=True, exist_ok=True)
    temp = state_file.with_suffix(".tmp")
    temp.write_text(json.dumps(state, indent=2))
    temp.replace(state_file)  # atomic on POSIX
```

**`--full` reset:** Delete `index-state.json` (or clear `processed_shas` and `last_indexed_sha`). Phase 6 captures use `source_description="git-commits"` (real-time) vs. `source_description="git-history-index"` (indexer); `--full` only clears indexer-tagged episodes from Kuzu, not Phase 6 captures.

### Pattern 3: Quality Gate — Commit Skip Filters

**What:** Before any LLM call, check whether a commit should be skipped entirely. This is the most important performance optimization — each skipped commit saves two LLM API calls.

**Bot commit detection (MEDIUM confidence — verified from GitHub community discussions):**

Known bot email patterns as of 2026:
- `dependabot[bot]@users.noreply.github.com`
- `41898282+github-actions[bot]@users.noreply.github.com` (ID varies by org)
- General pattern: `\d+\+[a-z\-]+\[bot\]@users\.noreply\.github\.com`
- Renovate bot: `renovate[bot]@users.noreply.github.com` or `renovate@whitesourcesoftware.com`

Bot commit message prefixes:
- `chore(deps):` (Dependabot)
- `chore(deps-dev):` (Dependabot dev)
- `build(deps):` (Dependabot)

```python
# Source: Synthesized from GitHub community docs + research
import re
from git import Commit

BOT_EMAIL_PATTERNS = [
    r'\[bot\]@users\.noreply\.github\.com$',
    r'@dependabot\.com$',
    r'noreply@github\.com$',
]
BOT_MESSAGE_PREFIXES = [
    'chore(deps):',
    'chore(deps-dev):',
    'build(deps):',
    'chore(release):',
]
VERSION_FILE_PATTERNS = ['package.json', 'pyproject.toml', '__version__', 'CHANGELOG']

def should_skip_commit(commit: Commit) -> tuple[bool, str]:
    """Returns (skip, reason) tuple."""
    # 1. Bot detection
    email = commit.author.email or ''
    for pattern in BOT_EMAIL_PATTERNS:
        if re.search(pattern, email, re.IGNORECASE):
            return True, f"bot_author:{email}"

    message = commit.message.strip()
    for prefix in BOT_MESSAGE_PREFIXES:
        if message.lower().startswith(prefix.lower()):
            return True, f"bot_message_prefix:{prefix}"

    # 2. Pure merge commits (no conflict resolution = empty diff)
    if len(commit.parents) > 1:
        stats = commit.stats.total
        if stats.get('files', 0) == 0:
            return True, "pure_merge_no_diff"

    # 3. Tiny commits (1-3 lines total)
    stats = commit.stats.total
    total_lines = stats.get('insertions', 0) + stats.get('deletions', 0)
    if total_lines <= 3:
        return True, f"tiny_commit:{total_lines}_lines"

    # 4. Version-bump-only commits
    changed_files = list(commit.stats.files.keys())
    if changed_files and all(
        any(pat in f for pat in VERSION_FILE_PATTERNS)
        for f in changed_files
    ):
        return True, "version_bump_only"

    return False, ""
```

### Pattern 4: Two-Pass LLM Extraction

**What:** For each qualifying commit, run two LLM passes: (1) structured Q&A that produces consistent baseline fields, (2) free-form entity extraction that catches unexpected signals. Results stored as separate `add_episode()` calls with different `source_description` tags.

**Why not merged into one episode:** The structured pass and free-form pass serve different retrieval purposes. Keeping them separate means the structured facts (what/why/which files) are always queryable without needing to parse free-form text.

```python
# Pattern — matches existing graphiti.add_episode() API (verified against graphiti-core 0.26.3)
# Source: src/graph/service.py existing pattern

STRUCTURED_EXTRACTION_PROMPT = """Analyze this git commit and answer concisely:

Commit: {sha_short}
Author: {author}
Message: {message}

Diff:
{diff_content}

Answer these questions:
1. What decision was made?
2. What was changed (components/files)?
3. Why was this change made (purpose/motivation)?
4. What was the impact or risk?
"""

FREE_FORM_EXTRACTION_PROMPT = """Extract all entities and relationships from this git commit.
Focus on: people, components, concepts, architectural decisions, bugs fixed, features added.
Format as natural language knowledge graph facts.

Commit: {sha_short} by {author}
Message: {message}

Diff summary:
{diff_content}
"""

async def extract_commit_knowledge(
    commit_sha: str,
    commit_message: str,
    commit_author: str,
    diff_content: str,
    graphiti_instance,
    group_id: str,
    reference_time: datetime,
) -> dict:
    """Two-pass extraction: structured + free-form, both stored via add_episode()."""
    from graphiti_core.nodes import EpisodeType

    # Pass 1: Structured Q&A
    structured_prompt = STRUCTURED_EXTRACTION_PROMPT.format(
        sha_short=commit_sha[:7],
        author=commit_author,
        message=commit_message,
        diff_content=diff_content[:4000],  # truncate for prompt
    )
    await graphiti_instance.add_episode(
        name=f"git-commit-structured-{commit_sha[:7]}",
        episode_body=structured_prompt,
        source_description=f"git-history-index:structured:{commit_sha[:7]}",
        reference_time=reference_time,
        source=EpisodeType.text,
        group_id=group_id,
    )

    # Pass 2: Free-form entity extraction
    freeform_prompt = FREE_FORM_EXTRACTION_PROMPT.format(
        sha_short=commit_sha[:7],
        author=commit_author,
        message=commit_message,
        diff_content=diff_content[:4000],
    )
    await graphiti_instance.add_episode(
        name=f"git-commit-freeform-{commit_sha[:7]}",
        episode_body=freeform_prompt,
        source_description=f"git-history-index:freeform:{commit_sha[:7]}",
        reference_time=reference_time,
        source=EpisodeType.text,
        group_id=group_id,
    )
```

### Pattern 5: Background Hook — Non-Blocking, Self-Contained

**What:** The post-merge, post-checkout, and post-rewrite hooks fire `graphiti index` in the background with output completely disconnected from the hook process. Hook exits in <100ms regardless of how long indexing takes.

**Verified pattern (from ylan.segal-family.com + Python subprocess docs):**

Shell template:
```bash
#!/bin/sh
# GRAPHITI_HOOK_START

# Skip if GRAPHITI_SKIP is set
[ "$GRAPHITI_SKIP" = "1" ] && exit 0

# Skip if graphiti not in PATH
command -v graphiti >/dev/null 2>&1 || exit 0

# Check if hooks enabled
graphiti config get hooks.enabled 2>/dev/null | grep -q "true" || exit 0

# Check cooldown (graphiti index handles this internally — just call it)
# Background: redirect all output to /dev/null, run in subshell, & to background
# The &>/dev/null & pattern disconnects stdout+stderr, allowing hook to exit immediately
(graphiti index 2>/dev/null) &

# Exit immediately — never block the user
exit 0
# GRAPHITI_HOOK_END
```

**Cooldown check — inside `graphiti index` (not in the shell script):**
```python
# src/indexer/state.py
from datetime import datetime, timezone, timedelta
import json
from pathlib import Path

COOLDOWN_MINUTES = 5  # Claude's discretion: 5 minute default

def is_within_cooldown(project_root: Path) -> bool:
    """Return True if last index run was within COOLDOWN_MINUTES."""
    state = load_state(project_root)
    last_run = state.get("last_run_at")
    if not last_run:
        return False
    last_run_dt = datetime.fromisoformat(last_run)
    elapsed = datetime.now(timezone.utc) - last_run_dt
    return elapsed < timedelta(minutes=COOLDOWN_MINUTES)
```

### Pattern 6: Large Diff Two-Pass Summarization

**What:** Commits above a line-change threshold first get diff summarized by a fast LLM call, then the summary goes through the two-pass extraction. This prevents LLM context window overflow for large commits.

**Size threshold (Claude's discretion — recommended: 300 lines total diff):**

Rationale for 300-line threshold:
- Phase 6 `fetch_commit_diff()` already truncates to 500 lines per file
- Typical LLM context: 8K–32K tokens; 300 diff lines ≈ 3,000–4,000 tokens, leaving room for prompts
- A 300-line diff is roughly a medium-sized feature commit
- Anything larger risks truncation artifacts in structured extraction

```python
LARGE_DIFF_THRESHOLD_LINES = 300

def get_diff_content(commit, project_root: Path) -> tuple[str, bool]:
    """Returns (diff_content, is_large) tuple.

    Uses existing fetch_commit_diff() from capture.git_capture when possible.
    Falls back to GitPython diff for accuracy.
    """
    from src.capture.git_capture import fetch_commit_diff

    try:
        diff_text = fetch_commit_diff(
            commit_sha=commit.hexsha,
            repo_path=project_root,
            max_lines_per_file=500,  # existing default
        )
        total_lines = diff_text.count('\n')
        is_large = total_lines > LARGE_DIFF_THRESHOLD_LINES
        return diff_text, is_large
    except Exception:
        return "", False
```

### Anti-Patterns to Avoid

- **Calling `commit.diff()` on every commit during iteration:** `diff()` hits disk/git I/O. Only call it AFTER the quality gate passes. Check `commit.stats.total` first (lighter) to detect tiny commits, then fetch full diff only for qualifying commits.
- **Storing processed SHAs in Kuzu metadata:** Requires the DB to be open/writable to update cursor, creating a circular dependency (can't check if something was indexed without opening the DB). Use the independent JSON state file instead.
- **Blocking the git hook on indexing completion:** The hook MUST exit in <100ms. The `(graphiti index ...) &` pattern with output disconnection is mandatory. Never use `subprocess.run()` in a hook script — use `subprocess.Popen()` with `close_fds=True` if calling from Python.
- **Running `graphiti index --full` from a hook:** `--full` is a user-initiated operation only. Hooks always call `graphiti index` (incremental).
- **Deleting Phase 6 episodes during `--full`:** The `--full` flag resets only episodes tagged with `source_description` containing `git-history-index:`. Phase 6 real-time captures (tagged `git-commits`) are never touched.
- **Removing the whole `src/gitops/` module:** `src/gitops/config.py` (gitignore generation), `src/gitops/hooks.py` (secrets scanning, size check), and `src/gitops/__init__.py` all have surviving code. Only specific functions/modules get deleted, not the entire directory.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Git history traversal | Custom `subprocess git log` parser | `repo.iter_commits()` from GitPython (already in deps) | GitPython already in deps; typed commit objects; handles encoding, merge commits, date parsing, parent resolution correctly |
| Per-commit diff fetching | Re-implement diff extraction | `fetch_commit_diff()` from `src/capture/git_capture.py` | Already implemented, tested, handles per-file truncation, merge commits, and error cases |
| LLM episode storage | Custom Kuzu write | `graphiti.add_episode()` via `GraphService.add()` | Already handles embeddings, entity extraction, relationship detection, group_id scoping |
| Progress UI | Custom spinner | `console.status()` from Rich (already in deps via typer[all]) | Already used in `hooks.py` install command; consistent UX |
| Atomic file writes | Manual temp file | `Path.replace()` (stdlib) — established in `checkpoint.py` | Atomic on POSIX; proven pattern already in this codebase |
| Hook installation | New installer | `_install_hook()` / `install_postmerge_hook()` from `src/hooks/installer.py` | Already handles idempotency, marker-based detection, non-destructive append; three new hook types just need new templates + new public functions added |
| Bot email detection | Full ML classifier | `re.search(BOT_EMAIL_PATTERNS, email)` | Sufficient for the known static set of bot email formats from GitHub/GitLab/Bitbucket; patterns are documented and stable |

**Key insight:** This phase reuses ~70% of existing infrastructure. The indexer is essentially a new control flow (`for commit in repo.iter_commits()`) that feeds into the existing `fetch_commit_diff()` → LLM → `add_episode()` pipeline.

---

## Common Pitfalls

### Pitfall 1: SHA Deduplication Set Grows Unboundedly

**What goes wrong:** `processed_shas` in `index-state.json` accumulates every SHA ever indexed. For a repo with 10,000 commits, this becomes a 640KB+ JSON file that is loaded and saved on every incremental run.

**Why it happens:** Naive implementation stores full 40-char SHAs as a flat list.

**How to avoid:** Store SHAs as a set (deduplicated) and truncate to 8-char short SHAs (collision probability negligible in a single repo). Or, use only `last_indexed_sha` as the cursor and rely on `iter_commits(until=last_indexed_sha)` to skip already-processed commits. Only fall back to full SHA set for `--since` mode which can process non-contiguous ranges.

**Recommended approach:** Use `last_indexed_sha` as primary cursor for incremental mode (tells GitPython to stop when it reaches that SHA). Use `processed_shas` set only as a secondary deduplication check for re-runs with `--since`. Cap `processed_shas` at 10,000 entries (trim oldest on overflow).

### Pitfall 2: `post-checkout` Fires on Every File Checkout

**What goes wrong:** `post-checkout` fires for BOTH branch switches (`git checkout branch`) AND individual file checkouts (`git checkout -- file.py`). Triggering a full background index on every file restore is wasteful.

**Why it happens:** git passes `$3` (the "checkout type" flag) to `post-checkout`: `1` for branch switch, `0` for file checkout. This is commonly overlooked.

**How to avoid:**
```bash
# In post-checkout.sh — check the third argument
if [ "$3" = "0" ]; then
    # File checkout, not branch switch — skip indexing
    exit 0
fi
# Branch switch — check for new unindexed commits and trigger background index
```

**Warning signs:** Hook log shows index triggered on every `git checkout -- .` or `git restore`.

### Pitfall 3: `--full` Deletes Phase 6 Real-Time Captures

**What goes wrong:** `graphiti index --full` is supposed to wipe all git-history-indexed knowledge and re-index. If implemented naively (delete all episodes in the project graph), it destroys Phase 6 conversation captures and real-time git captures too.

**Why it happens:** Episodes are stored by group_id (project name), not by source. A naive "wipe the project graph" deletes everything.

**How to avoid:** Tag all indexer-sourced episodes with a distinguishable `source_description` prefix (`git-history-index:`). The `--full` reset queries Kuzu for episodes where `source_description STARTS WITH 'git-history-index:'` and deletes only those. Phase 6 real-time captures use `source_description="git-commits"` (set in `git_worker.py`) — a different prefix.

**Critical code point:** `GraphService.add()` in `graph/service.py` generates `episode_name` with `cli_add_` prefix. The indexer must call `graphiti.add_episode()` directly (not via `GraphService.add()`) to control `source_description` precisely.

### Pitfall 4: GitPython `commit.stats` Is Expensive on Large Repos

**What goes wrong:** Calling `commit.stats` for every commit in a 50,000-commit repo causes thousands of git subprocess calls, making the initial index run take many minutes just to evaluate the quality gate.

**Why it happens:** GitPython's `Commit.stats` runs a git subprocess per commit to get diff statistics. This is O(N) subprocess calls.

**How to avoid:**
1. Use `commit.parents` length check first (pure Python, free) to detect pure merges
2. Use `commit.message` prefix check (pure Python, free) to detect bot commits
3. Only call `commit.stats` for commits that pass the message and parent checks
4. Consider using `git log --format="%H %ae %s" --numstat` via subprocess for bulk pre-filtering before GitPython detailed processing on large repos

**Warning signs:** Index startup takes >10 seconds before any LLM calls happen.

### Pitfall 5: Hook Template References `src.gitops.autoheal`

**What goes wrong:** The existing `post-merge.sh` template calls `src.gitops.autoheal.auto_heal()`. After Phase 7.1 removes `autoheal.py`, the hook becomes broken for any repo that had it installed from Phase 7.

**Why it happens:** Phase 7 installed hooks that reference now-deleted modules.

**How to avoid:** The new `post-merge.sh` template must reference only the new `graphiti index` CLI command (not any Python module directly). The hook installer must also support "upgrade" — detecting old Graphiti hook markers and replacing them with new templates. The `_install_hook()` function in `installer.py` already handles non-destructive append; a new `upgrade_hook()` function may be needed to replace the existing section.

**Warning signs:** After Phase 7.1, existing dev machines with Phase 7 hooks get `ModuleNotFoundError: No module named 'src.gitops.autoheal'` on every `git merge`.

### Pitfall 6: `iter_commits()` Without Bounds on Large Repos

**What goes wrong:** On a repo with 100,000 commits, `graphiti index` default (full history) triggers 100,000 quality-gate evaluations + potentially thousands of LLM calls. First run takes hours and costs significant API spend.

**Why it happens:** Default full history is correct for brownfield bootstrap but needs clear user communication.

**How to avoid:**
- Document that `graphiti index` on large brownfield repos should first be run with `--since 1year` or `--max-commits 500` to bootstrap recent history
- During the `graphiti index` run, show progress clearly: "Processing commit N of M total (estimated X minutes remaining)"
- The config keys `index.max_commits` and `index.since` serve this purpose — make sure they are read from `.graphiti/config.toml` before starting iteration

---

## Code Examples

Verified patterns from official sources and this codebase:

### Walking Git History and Extracting Diffs

```python
# Source: GitPython 3.1.46 official tutorial + existing src/capture/git_capture.py
import git
from pathlib import Path
from datetime import datetime, timezone

def iterate_commits_for_indexing(
    project_root: Path,
    since_sha: str | None = None,
    max_count: int | None = None,
    since_date: str | None = None,
):
    """Yield commits from HEAD backwards, stopping at since_sha if provided."""
    repo = git.Repo(project_root, search_parent_directories=True)

    kwargs = {}
    if max_count:
        kwargs['max_count'] = max_count
    if since_date:
        kwargs['since'] = since_date  # e.g. "2025-01-01" or "1.year.ago"

    for commit in repo.iter_commits(**kwargs):
        # Stop at already-processed SHA (incremental mode cursor)
        if since_sha and commit.hexsha == since_sha:
            break

        yield commit
```

### Quality Gate Integration

```python
# Combine cheap checks before expensive ones
def should_process_commit(commit) -> bool:
    # Cheap checks first (no I/O)
    if len(commit.parents) > 1 and not _has_conflict_resolution(commit):
        return False  # pure merge

    email = (commit.author.email or '').lower()
    if '[bot]' in email or 'noreply@github.com' in email:
        return False  # bot commit

    message = commit.message.strip().lower()
    for prefix in BOT_MESSAGE_PREFIXES:
        if message.startswith(prefix.lower()):
            return False

    # More expensive: stats (requires git subprocess)
    try:
        stats = commit.stats.total
        total_lines = stats.get('insertions', 0) + stats.get('deletions', 0)
        if total_lines <= 3:
            return False  # tiny commit

        # Version bump: only version files changed
        changed_files = list(commit.stats.files.keys())
        if changed_files and _is_version_bump_only(changed_files):
            return False

    except Exception:
        pass  # On stats error, process the commit (fail open)

    return True

def _has_conflict_resolution(commit) -> bool:
    """Check if merge commit has actual conflict resolution content."""
    try:
        stats = commit.stats.total
        return stats.get('files', 0) > 0
    except Exception:
        return False  # assume no conflict resolution on error
```

### New Hook Templates

```bash
# src/hooks/templates/post-merge.sh (REPLACED)
#!/bin/sh
# GRAPHITI_HOOK_START
[ "$GRAPHITI_SKIP" = "1" ] && exit 0
command -v graphiti >/dev/null 2>&1 || exit 0
graphiti config get hooks.enabled 2>/dev/null | grep -q "true" || exit 0

# Background index with output disconnected — never block merge
(graphiti index >/dev/null 2>&1) &
exit 0
# GRAPHITI_HOOK_END
```

```bash
# src/hooks/templates/post-checkout.sh (NEW)
#!/bin/sh
# GRAPHITI_HOOK_START
[ "$GRAPHITI_SKIP" = "1" ] && exit 0
command -v graphiti >/dev/null 2>&1 || exit 0
graphiti config get hooks.enabled 2>/dev/null | grep -q "true" || exit 0

# $3 = 0 means file checkout (not branch switch) — skip
[ "$3" = "0" ] && exit 0

# Branch switch — background index
(graphiti index >/dev/null 2>&1) &
exit 0
# GRAPHITI_HOOK_END
```

```bash
# src/hooks/templates/post-rewrite.sh (NEW)
#!/bin/sh
# GRAPHITI_HOOK_START
[ "$GRAPHITI_SKIP" = "1" ] && exit 0
command -v graphiti >/dev/null 2>&1 || exit 0
graphiti config get hooks.enabled 2>/dev/null | grep -q "true" || exit 0

# Background index after rebase/amend
(graphiti index >/dev/null 2>&1) &
exit 0
# GRAPHITI_HOOK_END
```

### `graphiti index` CLI Command Skeleton

```python
# src/cli/commands/index.py — new command
# Pattern follows existing hooks.py and compact.py command structure

import typer
from typing import Annotated, Optional
from pathlib import Path
from rich.progress import Progress, SpinnerColumn, TextColumn

from src.cli.output import console, print_success, print_error
from src.cli.utils import resolve_scope, EXIT_SUCCESS, EXIT_ERROR

def index_command(
    full: Annotated[bool, typer.Option("--full", help="Wipe all git-indexed knowledge and re-process entire history")] = False,
    since: Annotated[Optional[str], typer.Option("--since", help="Index commits since date (YYYY-MM-DD) or SHA")] = None,
    verbose: Annotated[bool, typer.Option("--verbose", "-v", help="Show detailed progress")] = False,
):
    """Index git history into the knowledge graph.

    Incremental by default — only processes commits not yet indexed.
    Use --full to wipe and re-index entire history.
    Use --since to index from a specific date or SHA.
    """
    from src.indexer import GitIndexer  # new module

    scope, root = resolve_scope()
    if root is None:
        print_error("Not in a git repository. Cannot index git history.")
        raise typer.Exit(EXIT_ERROR)

    indexer = GitIndexer(project_root=root, scope=scope)

    if full:
        console.print("[yellow]Wiping all git-indexed knowledge...[/yellow]")
        indexer.reset_full()

    with console.status("[cyan]Indexing git history...[/cyan]") as status:
        result = indexer.run(since=since, verbose=verbose, status_callback=status.update)

    print_success(
        f"Indexed {result['commits_processed']} commits, "
        f"extracted {result['entities_created']} entities "
        f"in {result['elapsed_seconds']:.1f}s"
    )
```

### Removing Journal References from `compact.py`

The existing `src/cli/commands/compact.py` has `--journal` flag and imports from `src.gitops.compact`. These are removed. The remaining compact command retains only graph-level deduplication (which calls `GraphService.compact()`). The `--journal`, `--ttl-days`, `--dry-run` flags tied to journal behavior are removed.

### Updated Pre-commit Hook (Preserving Secrets + Size)

The `pre-commit.sh` template keeps secrets scanning and size checks but removes journal staging and schema validation:

```python
# Surviving functions from src/gitops/hooks.py (refactored):
# - check_graphiti_size() — KEEP unchanged
# - scan_staged_secrets()  — RENAME from scan_journal_secrets(), remove journal dir filter

# scan_staged_secrets scans ANY staged file (not just journal/) using detect-secrets baseline
# This is actually MORE useful than the journal-specific version
```

---

## What Gets Deleted vs. What Gets Modified

### Deleted (entire files)

| File | Reason |
|------|--------|
| `src/gitops/journal.py` | Journal entry model + writer — entire purpose removed |
| `src/gitops/lfs.py` | LFS detection and setup helpers — entire purpose removed |
| `src/gitops/checkpoint.py` | Checkpoint tracking — entire purpose removed |
| `src/gitops/replay.py` | Journal replay engine — entire purpose removed |
| `src/gitops/autoheal.py` | Post-merge journal auto-heal — entire purpose removed |
| `src/gitops/compact.py` | Journal compaction — entire purpose removed |

### Modified (partial changes)

| File | What Changes |
|------|-------------|
| `src/gitops/__init__.py` | Remove all exports of deleted modules; keep `config`, keep surviving `hooks` functions |
| `src/gitops/config.py` | Remove `generate_gitattributes()` and LFS-related `GRAPHITI_GITATTRIBUTES` constant; keep `generate_gitignore()` and `ensure_git_config()` (gitignore part only) |
| `src/gitops/hooks.py` | Remove `stage_journal_entries()`, `validate_journal_schemas()`, `scan_journal_secrets()`, `run_precommit_validation()` journal orchestration; keep `check_graphiti_size()` and rename `scan_journal_secrets()` → `scan_staged_secrets()` (broader scope) |
| `src/hooks/templates/post-merge.sh` | Replace journal replay call with `graphiti index` background call |
| `src/hooks/templates/pre-commit.sh` | Remove journal staging and schema validation; keep secrets scan + size check |
| `src/hooks/installer.py` | Add `install_postcheckout_hook()`, `install_postrewrite_hook()` functions; add `upgrade_hook()` to replace old journal-based post-merge with new indexer-based one |
| `src/cli/commands/compact.py` | Remove `--journal`, `--ttl-days`, `--dry-run` flags and all `src.gitops.compact` imports and usage |
| `src/cli/__init__.py` | Register new `index` command |

### New Files

| File | Purpose |
|------|---------|
| `src/indexer/__init__.py` | Module exports |
| `src/indexer/indexer.py` | `GitIndexer` class — main control flow |
| `src/indexer/state.py` | JSON state file management (cursor, deduplication set, cooldown) |
| `src/indexer/quality_gate.py` | `should_skip_commit()` + all filter helpers |
| `src/indexer/extraction.py` | Two-pass LLM extraction per commit |
| `src/hooks/templates/post-checkout.sh` | NEW hook template |
| `src/hooks/templates/post-rewrite.sh` | NEW hook template |
| `src/cli/commands/index.py` | `graphiti index` command |

---

## State of the Art

| Old Approach (Phase 7) | New Approach (Phase 7.1) | Impact |
|------------------------|--------------------------|--------|
| Journal files in `.graphiti/journal/` committed to git | `.graphiti/` fully gitignored — no knowledge ever in git | Eliminates LFS complexity, merge conflicts, journal file bloat, multi-developer sync issues |
| Checkpoint tracks last-applied journal entry (filename-based) | SHA cursor tracks last-indexed commit (git-native identity) | SHA is the natural identity for git commits; no collision risk; resumption is exact |
| Auto-heal replays journal entries after merge | Auto-index runs `graphiti index` incrementally after merge | Simpler, faster, no journal to replay; same result (knowledge graph updated) |
| Pre-commit stages journal entries | Pre-commit scans all staged files for secrets + size | Broader protection; not limited to journal directory |
| `graphiti compact --journal` cleans up TTL-expired entries | No journal to compact; `graphiti compact` is graph-only | Simpler mental model; no TTL lifecycle to manage |

**Deprecated/obsoleted by this phase:**
- **LFS tracking:** Entire Git LFS setup removed. No need to check `is_lfs_pointer()` or run `git lfs pull`. The `.gitattributes` LFS entry for `.graphiti/database/**` is removed.
- **Journal entry schema version:** `JournalEntry` Pydantic model with `version: "1.0"` field — no longer needed.
- **`GRAPHITI_SKIP=1` for journal bypass:** `GRAPHITI_SKIP=1` still works for the pre-commit hook (skips secrets/size checks), but journal-specific bypass meaning is gone.

---

## Open Questions

### 1. SHA Cursor: `last_indexed_sha` vs. Full SHA Set

**What we know:** Incremental mode needs to know where to resume. `--since` mode needs deduplication across non-contiguous SHA ranges.

**What's unclear:** Whether `iter_commits(until=last_sha)` stops correctly at the exact SHA or requires the entry after it. GitPython docs are ambiguous on whether `until` is exclusive or inclusive.

**Recommendation:** Test empirically with a small fixture repo. If `until` is inclusive (includes the SHA), stop the loop manually when `commit.hexsha == last_indexed_sha` (pattern shown in code examples above). This is safer than relying on `until` semantics.

### 2. `--full` Episode Deletion from Kuzu

**What we know:** `--full` must delete only `git-history-index:` tagged episodes from Kuzu. The deletion API is `Node.delete_by_uuids()` (used in `GraphService.delete_entities()`).

**What's unclear:** Whether Kuzu supports querying by `source_description` prefix. The existing schema stores `source_description` on the `Episodic` node type.

**Recommendation:** Before building `--full`, verify with a Kuzu query:
```python
records, _, _ = await driver.execute_query(
    """
    MATCH (e:Episodic)
    WHERE e.group_id = $group_id AND e.source STARTS WITH 'git-history-index:'
    RETURN e.uuid AS uuid
    """,
    group_id=group_id,
)
```
If `STARTS WITH` is not supported in Kuzu's Cypher dialect, use `CONTAINS 'git-history-index'` instead. Verify before implementing.

### 3. `index-state.json` Gitignore Coverage

**What we know:** `.graphiti/` is already in the root `.gitignore` with a simple `/.graphiti/` entry. The `index-state.json` file would be inside `.graphiti/`.

**What's unclear:** Whether the root `.gitignore` pattern `/.graphiti/` or `.graphiti/` (current entry) covers the nested `index-state.json` file in all git configurations.

**Recommendation:** The current `.gitignore` has `.graphiti/` (no leading slash), which covers all `.graphiti/` directories recursively. This is correct. Verify by running `git check-ignore .graphiti/index-state.json` after creating the file.

### 4. Hook Upgrade Path for Existing Phase 7 Installations

**What we know:** Phase 7 installed post-merge hooks that call `src.gitops.autoheal.auto_heal()`. After Phase 7.1 deletes `autoheal.py`, those hooks break.

**What's unclear:** Whether the planner should include a migration step that detects Phase 7 hooks by marker content and replaces them.

**Recommendation:** Add an upgrade task. In `installer.py`, add an `upgrade_postmerge_hook()` function that detects the old marker pattern (`from src.gitops.autoheal import auto_heal`) and replaces the entire graphiti section with the new `graphiti index` template. This runs automatically when `graphiti hooks install` is called if the old template is detected.

---

## Sources

### Primary (HIGH confidence)

- GitPython 3.1.46 official tutorial — https://gitpython.readthedocs.io/en/stable/tutorial.html — `iter_commits()`, Commit object properties, diff API
- GitPython 3.1.46 API reference — https://gitpython.readthedocs.io/en/stable/reference.html — `Repo.iter_commits()` parameters, `Commit.stats`, `Commit.diff()`
- graphiti-core 0.26.3 — verified via installed package in `.venv/` — `add_episode()` signature with `source_description`, `EpisodeType`, `group_id` confirmed
- Python stdlib `subprocess` docs — https://docs.python.org/3/library/subprocess.html — `Popen` with `close_fds` for background execution
- Existing codebase: `src/capture/git_capture.py` — `fetch_commit_diff()` API and `read_and_clear_pending_commits()` — directly reusable
- Existing codebase: `src/gitops/checkpoint.py` — atomic write pattern via `Path.replace()` — directly applicable to SHA cursor storage
- Existing codebase: `src/hooks/installer.py` — `_install_hook()`, marker-based idempotency — directly extensible for three new hook types
- Existing codebase: `src/graph/service.py` — `GraphService.add()` and `add_episode()` usage — indexer plugs into same pipeline

### Secondary (MEDIUM confidence)

- GitHub community discussion on bot email patterns — https://github.com/orgs/community/discussions/26560 — confirmed `41898282+github-actions[bot]@users.noreply.github.com` and `dependabot[bot]@users.noreply.github.com`
- GitHub Actions bot email reference — https://www.junian.net/dev/github-actions-bot-username-email-address/ — confirmed numeric ID prefix pattern
- Background long-running git hooks pattern — https://ylan.segal-family.com/blog/2022/05/21/background-long-running-git-hooks/ — `(command &>/dev/null) &` pattern with lockfile; subshell output disconnection confirmed
- CodeSignal Git History Extraction with Python — https://codesignal.com/learn/courses/database-setup-and-code-ingestion/lessons/git-history-extraction-with-python — `iter_commits()` usage pattern

### Tertiary (LOW confidence — for awareness only)

- General SQLite WAL pattern discussion — sqlite.org/forum — noted as alternative to JSON file for cursor storage; not recommended for this phase

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — All libraries already in project dependencies; no new installs required; verified versions confirmed
- Architecture: HIGH — Built on existing, tested patterns from this codebase (checkpoint atomic write, hook installer markers, git_capture diff fetching, add_episode API)
- Pitfalls: HIGH for known pitfalls (post-checkout $3 flag, autoheal module reference, --full episode scoping); MEDIUM for performance pitfall (commit.stats cost on large repos — logical but untested at scale in this repo)
- Bot detection patterns: MEDIUM — Verified email formats from GitHub official community discussions; message prefix patterns from Dependabot docs; regex patterns are reasonable but may miss some bots

**Research date:** 2026-02-20
**Valid until:** 2026-04-20 (60 days — git hook APIs and GitPython are stable; graphiti-core API should remain stable at 0.26.3)

**Key findings:**
1. No new pip dependencies required — entire indexer buildable from existing deps (GitPython, graphiti-core, structlog, typer, Rich)
2. `fetch_commit_diff()` from Phase 6 is directly reusable for the indexer's diff extraction step
3. The `_install_hook()` framework in `installer.py` handles all three new hook types (post-merge replacement, post-checkout new, post-rewrite new) with minimal additions
4. SHA cursor stored as JSON file is the right choice — zero-dependency, atomic writes via existing `Path.replace()` pattern, easily wiped for `--full`
5. The `post-checkout` hook requires checking `$3` argument to distinguish branch switches from file checkouts — a critical, commonly-missed detail
6. `--full` must use `source_description` prefix filtering in Kuzu to avoid deleting Phase 6 real-time captures — Kuzu query support for this needs pre-implementation verification
7. Existing Phase 7 post-merge hooks referencing `src.gitops.autoheal` will break after deletion — an upgrade path in `installer.py` is needed
